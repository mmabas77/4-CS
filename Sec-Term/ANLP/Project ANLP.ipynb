{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e642837-8a5b-4220-8f32-6f5ce42700d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- ----- Importing Section ----- ----- \n",
    "# Data libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ML Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import pickle\n",
    "from sklearn import metrics\n",
    "# My utils\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from utils import df_utils\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from utils import nlp_utils\n",
    "\n",
    "\n",
    "# ----- ----- ----- END ----- ----- ----- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43d36673-53d9-449b-9bf7-7af46e3a7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    df = df_utils.csv_to_dataframe(pd, './dataset/processed_data.csv')\n",
    "    df = df.sample(frac=1)\n",
    "    df.reset_index(inplace=True)\n",
    "    df.drop([\"index\"], axis=1, inplace=True)\n",
    "    df.rename(columns={'Content': 'text'}, inplace=True)\n",
    "    df.rename(columns={'Category': 'c'}, inplace=True)\n",
    "    # Todo : Remove this in production code\n",
    "    # df = df[:3]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1415cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_frame():\n",
    "    # Read data\n",
    "    df = read_data()\n",
    "    # Explore & Plot - 1\n",
    "    explore_and_plot_df(df)\n",
    "    # Enhance\n",
    "    df = enhance(df)\n",
    "    # Explore & Plot - 2\n",
    "    explore_and_plot_df(df)\n",
    "    # Return\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0127015e-07b1-4f62-a7a6-1d9fd37725da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance(df):\n",
    "    df = df_utils.drop_cols_with_names(df, 'Title', 'Link')\n",
    "    df = df_utils.drop_rows_with_null(df)\n",
    "    # Corpus calculations as text\n",
    "    df = process_df_text(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e6c2759-052b-457a-9553-e466dc0cd448",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df_text(df):\n",
    "    # Lowercase\n",
    "    # df['text'] = df['text'].str.lower()\n",
    "\n",
    "    # Stopwords\n",
    "    # df['stopwords'] = df.apply(\n",
    "    #     lambda row: nlp_utils.count_stopwords(row['text']),\n",
    "    #     axis=1\n",
    "    # )\n",
    "    # df['text'] = df.apply(\n",
    "    #     lambda row: nlp_utils.remove_stopwords(row['text']),\n",
    "    #     axis=1\n",
    "    # )\n",
    "\n",
    "    # Punctuations\n",
    "    # df['punctuations'] = df.apply(\n",
    "    #     lambda row: nlp_utils.count_punctuation(row['text']),\n",
    "    #     axis=1\n",
    "    # )\n",
    "    df['text'] = df.apply(\n",
    "        lambda row: nlp_utils.remove_punctuation(row['text']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Stem\n",
    "    df['text_stem'] = df.apply(\n",
    "        lambda row: nlp_utils.isir_stemmer(row['text']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Lem\n",
    "    # df['text_lem'] = df.apply(\n",
    "    #     lambda row: nlp_utils.word_net_lemmatizer(row['text']),\n",
    "    #     axis=1\n",
    "    # )\n",
    "\n",
    "    # print('\\n\\n 3-gram')\n",
    "    # df['3gram'] = nlp_utils.counter_gram(df['text_stem'],3)\n",
    "    #\n",
    "    # print('\\n\\n 1-gram')\n",
    "    # df['1gram'] = nlp_utils.counter_gram(df['text_stem'],1)\n",
    "    # print('\\n\\n 2-gram')\n",
    "    # df['2gram'] = nlp_utils.counter_gram(df['text_stem'],2)\n",
    "\n",
    "    print(df.head())\n",
    "    df = df_utils.drop_col_with_name(df, \"text\")\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a24d9d46-7d91-433e-994c-5883104fc8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_and_plot_df(df):\n",
    "    df_utils.print_dataframe_essential_info(df, np)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62f8af6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_extraction_binary_transform(df):\n",
    "    df = df_utils.drop_rows_with_null(df)\n",
    "\n",
    "    vectorization = CountVectorizer(binary=True)\n",
    "\n",
    "    xv_train = vectorization.fit_transform(df['text_stem'])\n",
    "    y = df['c']\n",
    "\n",
    "    return xv_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86cc513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_CountVectorize(df):\n",
    "    df = df_utils.drop_rows_with_null(df)\n",
    "\n",
    "    vectorization = CountVectorizer()\n",
    "\n",
    "    xv_train = vectorization.fit_transform(df['text_stem'])\n",
    "    y = df['c']\n",
    "\n",
    "    return xv_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e88e907",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction_TfidfVectorize(df):\n",
    "    df = df_utils.drop_rows_with_null(df)\n",
    "\n",
    "    vectorization = TfidfVectorizer()\n",
    "\n",
    "    xv_train = vectorization.fit_transform(df['text_stem'])\n",
    "    y = df['c']\n",
    "\n",
    "    return xv_train, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6bed56b-0895-44ca-bb59-6c99ff312997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(x_train, y_train):\n",
    "    \"\"\"\n",
    "    Using Two Models MultinomialNB return as NVB & SVC return as SCV\n",
    "    \"\"\"\n",
    "    NVB = MultinomialNB()\n",
    "    NVB.fit(x_train, y_train)\n",
    "    SCV = SVC(gamma='auto')\n",
    "    SCV.fit(x_train, y_train)\n",
    "    RFC = RandomForestClassifier(random_state=0)\n",
    "    RFC.fit(x_train, y_train)\n",
    "\n",
    "    return NVB, SCV, RFC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f09bb85b-683c-434d-bec7-e7eed3154579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    pickle.dump(model, open(path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ce20a14-0ea3-41aa-a037-c0d00efb69dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model_path, x_test):\n",
    "    loaded_model = pickle.load(open(model_path, 'rb'))\n",
    "    predictions = loaded_model.predict(x_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3af14bac-f114-4e66-be8b-ef1e1a0eb59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model_path, x_test, y_test):\n",
    "    loaded_model = pickle.load(open(model_path, 'rb'))\n",
    "    result = loaded_model.score(x_test, y_test)\n",
    "    y_hat = loaded_model.predict(x_test)\n",
    "    print(metrics.confusion_matrix(y_test, y_hat))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2c65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_binary_encoding():\n",
    "    X, y = feature_extraction_binary_transform(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    NVB, SVC, RFC = train_model(X_train, y_train)\n",
    "    save_model(NVB, 'NVB.sav')\n",
    "    save_model(SVC, 'SVC.sav')\n",
    "    save_model(RFC, 'RFC.sav')\n",
    "    #make_predictions('NVB.sav',x_test)\n",
    "    #NVB\n",
    "    print('Naive Bayes Accuracy\\n\\n')\n",
    "    print(evaluation('NVB.sav', X_test, y_test))\n",
    "    print('SVC Accuracy\\n\\n')\n",
    "    print(evaluation('SVC.sav', X_test, y_test))\n",
    "    print('RFC Accuracy\\n\\n')\n",
    "    print(evaluation('RFC.sav', X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5183577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_CountVectorize():\n",
    "    X, y = feature_extraction_CountVectorize(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    NVB, SVC, RFC = train_model(X_train, y_train)\n",
    "    save_model(NVB, 'NVB.sav')\n",
    "    save_model(SVC, 'SVC.sav')\n",
    "    save_model(RFC, 'RFC.sav')\n",
    "    #make_predictions('NVB.sav',x_test)\n",
    "    #NVB\n",
    "    print('Naive Bayes Accuracy\\n\\n')\n",
    "    print(evaluation('NVB.sav', X_test, y_test))\n",
    "    print('SVC Accuracy\\n\\n')\n",
    "    print(evaluation('SVC.sav', X_test, y_test))\n",
    "    print('RFC Accuracy\\n\\n')\n",
    "    print(evaluation('RFC.sav', X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8044cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_TfidfVectorize():\n",
    "    X, y = feature_extraction_TfidfVectorize(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    NVB, SVC, RFC = train_model(X_train, y_train)\n",
    "    save_model(NVB, 'NVB.sav')\n",
    "    save_model(SVC, 'SVC.sav')\n",
    "    save_model(RFC, 'RFC.sav')\n",
    "    #make_predictions('NVB.sav',x_test)\n",
    "    #NVB\n",
    "    print('Naive Bayes Accuracy\\n\\n')\n",
    "    print(evaluation('NVB.sav', X_test, y_test))\n",
    "    print('SVC Accuracy\\n\\n')\n",
    "    print(evaluation('SVC.sav', X_test, y_test))\n",
    "    print('RFC Accuracy\\n\\n')\n",
    "    print(evaluation('RFC.sav', X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7e5ce96-8b9b-4303-9768-306d26393db1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# if __name__ == \"__main__\":\n",
    "# nlp_utils.download_book()\n",
    "# df = prepare_data_frame()\n",
    "#vocab = sorted(set(word for sentence in df['text_stem'] for word in sentence.split()))\n",
    "# print('binary_encoding\\n\\n')\n",
    "# main_binary_encoding()\n",
    "# print('CountVectorize\\n\\n')\n",
    "# main_CountVectorize()\n",
    "# print('TfidfVectorize\\n\\n')\n",
    "# main_TfidfVectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data frame shape: (8399, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8399 entries, 0 to 8398\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Title   8399 non-null   object\n",
      " 1   text    8386 non-null   object\n",
      " 2   Link    8399 non-null   object\n",
      " 3   c       8399 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 262.6+ KB\n",
      "Data frame info: None\n",
      "\n",
      "---Data Correlation ---\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "---Data frame null count ---\n",
      "Title     0\n",
      "text     13\n",
      "Link      0\n",
      "c         0\n",
      "dtype: int64\n",
      "\n",
      "Total values : 33596\n",
      "Total missing values : 13\n",
      "Remaining : 33583\n",
      "\n",
      "Remaining percentage : 99.96130491725205%\n",
      "Missing percentage : 0.03869508274794618%\n",
      "---\n",
      "                                                text                c  \\\n",
      "0  اكتشف باحثون للتو يكون ساهم مرض غامض يقتل الشم...  علوم وتكنولوجيا   \n",
      "1  وقد اسفرت التفجيرات المدمره هزت مرفا بيروت 4 ا...             أخرى   \n",
      "2  وفي بيان صحفي قال انطونيو غوتيريش ان الوضع ناج...             أخرى   \n",
      "3  عزيزي القارء اعرفك بنفسي اخوك سعود بن عبدالرحم...      ريادة أعمال   \n",
      "4  اجري الخبراء عمليات محاكاه حاسوبيه اجل تحديد ا...  علوم وتكنولوجيا   \n",
      "\n",
      "                                           text_stem  \n",
      "0  كشف بحث لتو يكون سهم مرض غمض قتل شمبانز حمه Si...  \n",
      "1  وقد سفر فجر دمر هزت رفا يرو 4 اب غسطس دمر عظم ...  \n",
      "2  وفي بين صحف قال طونيو غوتيريش ان وضع نجم عدد ا...  \n",
      "3  عزز قرء عرف نفس اخك سعد بن عبدالرحمن شرف حبت و...  \n",
      "4  اجر خبراء عمل حكا حسب اجل حدد جزء نتج طبع ادي ...  \n",
      "Data frame shape: (8386, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8386 entries, 0 to 8398\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   c          8386 non-null   object\n",
      " 1   text_stem  8386 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 196.5+ KB\n",
      "Data frame info: None\n",
      "\n",
      "---Data Correlation ---\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "---Data frame null count ---\n",
      "c            0\n",
      "text_stem    0\n",
      "dtype: int64\n",
      "\n",
      "Total values : 16772\n",
      "Total missing values : 0\n",
      "Remaining : 16772\n",
      "\n",
      "Remaining percentage : 100.0%\n",
      "Missing percentage : 0.0%\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "df = prepare_data_frame()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryEncoding\n",
      "\n",
      "\n",
      "Naive Bayes Accuracy\n",
      "\n",
      "\n",
      "[[836   4   1]\n",
      " [  8 835   4]\n",
      " [ 32  44 752]]\n",
      "0.9630365659777425\n",
      "SVC Accuracy\n",
      "\n",
      "\n",
      "[[453   0 388]\n",
      " [ 21  69 757]\n",
      " [  3   0 825]]\n",
      "0.5353736089030207\n",
      "RFC Accuracy\n",
      "\n",
      "\n",
      "[[819   7  15]\n",
      " [  8 820  19]\n",
      " [ 14  21 793]]\n",
      "0.9666136724960255\n"
     ]
    }
   ],
   "source": [
    "print('BinaryEncoding\\n\\n')\n",
    "main_binary_encoding()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorize\n",
      "\n",
      "\n",
      "Naive Bayes Accuracy\n",
      "\n",
      "\n",
      "[[831   6   4]\n",
      " [  5 835   7]\n",
      " [ 15  34 779]]\n",
      "0.9717806041335453\n",
      "SVC Accuracy\n",
      "\n",
      "\n",
      "[[708   8 125]\n",
      " [  8 629 210]\n",
      " [  7  15 806]]\n",
      "0.8517488076311606\n",
      "RFC Accuracy\n",
      "\n",
      "\n",
      "[[824   7  10]\n",
      " [  9 820  18]\n",
      " [ 14  28 786]]\n",
      "0.965818759936407\n"
     ]
    }
   ],
   "source": [
    "print('CountVectorize\\n\\n')\n",
    "main_CountVectorize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorize\n",
      "\n",
      "\n",
      "Naive Bayes Accuracy\n",
      "\n",
      "\n",
      "[[840   1   0]\n",
      " [ 20 824   3]\n",
      " [ 55  38 735]]\n",
      "0.9534976152623211\n",
      "SVC Accuracy\n",
      "\n",
      "\n",
      "[[  0   0 841]\n",
      " [  0   0 847]\n",
      " [  0   0 828]]\n",
      "0.32909379968203495\n",
      "RFC Accuracy\n",
      "\n",
      "\n",
      "[[829   5   7]\n",
      " [  8 824  15]\n",
      " [ 11  20 797]]\n",
      "0.9737678855325914\n"
     ]
    }
   ],
   "source": [
    "print('TfidfVectorize\\n\\n')\n",
    "main_TfidfVectorize()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}